{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumpLusWu/CIS700/blob/master/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GK7XEDAs-aoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone Git (0 pts)"
      ]
    },
    {
      "metadata": {
        "id": "X0PN1qeC-Qu4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following to get the required files needed for this assignment. "
      ]
    },
    {
      "metadata": {
        "id": "6C1SLvlD7tzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5b900fd3-367b-4b98-c92c-7b2f25ae4106"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cis700/hw1-release.git\n",
        "!mv hw1-release/dills/* .\n",
        "!mv hw1-release hw1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hw1-release'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 6), reused 23 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sin2bVyRSdP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classical vs. Deep Learning Approach\n"
      ]
    },
    {
      "metadata": {
        "id": "55fvftr2QDm-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 1. Using Decision Trees to Classify Fashion-MNIST (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "58yJGsmVSkMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Understanding the Dataset**\n",
        "\n",
        "The first step to machine learning is to understand the dataset that you're given. Therefore, familiarize yourself with the Fashion-MNIST dataset. We recommend reading the paper published about the dataset, which is detailed [here](https://arxiv.org/pdf/1708.07747.pdf).\n",
        "\n",
        "**Q1a (2 pts):** Explain at a high level what the dataset is (i.e. what are the specifications of the input data and associated labels)."
      ]
    },
    {
      "metadata": {
        "id": "iINHYwaCrRwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "he input data comes from the pictures of fashion products and is preprocessed to have the same image size as the MINST dataset. It has ten different classes and is labeled using numbers."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jGrylNPlHxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the Data**\n",
        "\n",
        "Since there's no built in dataloader for Fashion-MNIST built into sci-kit learn, we've created a dataloader that you may use. The first code snippet is to the install [wget](https://pypi.org/project/wget/) and sets up the directory structure for your data to go in.\n",
        "\n",
        "In the second code snippet, we provide the function made by the authors of the fashion-MNIST dataset to extract the downloaded data.\n",
        "\n",
        "**Q1b (3 pts):** Fill in the load_datasets function such that it returns the training data, training labels, testing data, and testing labels. In your report, indicate the dimensions of the training set and the testing set respectively. "
      ]
    },
    {
      "metadata": {
        "id": "wawpPWtf0dtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "52ecb296-88b5-4287-f95b-650a53b534eb"
      },
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!mkdir -p data/fashion"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mOBZr3rLTW46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import wget\n",
        "import pdb\n",
        "\n",
        "## Function provided by the creators of Fashion-MNIST to unpack and load their data\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MLQSFsdUfNA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fill in this method to load the Fashion-MNIST dataset\n",
        "def load_datasets():\n",
        "  base_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
        "  files = [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]\n",
        "  fashion_dir = \"data/fashion\"\n",
        "  import wget\n",
        "  base_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
        "  files = [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]\n",
        "  for i in range(4):\n",
        "    wget.download(base_URL+files[i], 'data/fashion') # download the compressed data file\n",
        "  train_images, train_labels =load_mnist('data/fashion', kind='train')\n",
        "  test_images, test_labels=  load_mnist('data/fashion', kind='t10k')\n",
        "  # Return the correct four variables\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrYD0bvhsnYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "273a162e-1285-461b-907f-3d870384183e"
      },
      "cell_type": "code",
      "source": [
        "print(train_images\n",
        "     )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cguJWQUzsnCc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AlnqKnqBmCiB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating a Classical Classifier**\n",
        "\n",
        "**Q1c (5 pts):** Use logistic regression to classify the Fashion-MNIST dataset. Note that because this is not sped up by a GPU this may take a few minutes to run. In your report, plot the learning curve for train and validation accuracy and report the final classification accuracy.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fKhoD8PQ9fAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmsoPT5Cmo7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 2. Using Deep Learning to Classify Fashion-MNIST (10 pts)\n",
        "\n",
        "In this section you will also classify the Fashion-MNIST dataset, however, with a deep neural network instead.\n",
        "\n",
        "**Downloading PyTorch**\n",
        "\n",
        "Run the code snippet below to install PyTorch / required packages and set up the GPU."
      ]
    },
    {
      "metadata": {
        "id": "R7YYE8Wm7aml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Required packages\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image\n",
        "\n",
        "## Add any other packages you may need below"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2EVPAWLR3W3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M5dETVerGj_2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PyTorch Tensorboard Integration**\n",
        "\n",
        "In this class we present the option of using tensorboard to visualize loss / accuracy plots and images. You may choose to use matplotlib instead, however, we recommend using tensorboard as it's becoming the industry standard for analyzing / debugging neural networks. \n",
        "\n",
        "Simply run the code snippets below in the order provided, and click on the link to open up the tensorboard dashboard (which should be blank right now!)."
      ]
    },
    {
      "metadata": {
        "id": "7oiaJ44FDxmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoJmRjNmF8HL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c842voLNGJdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-G5XfE0HQFFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To see how to use Pytorch with tensorboard, check out [this](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/tensorboard/main.py) github repo (specifically in main.py). Try plotting something using tensorboard to ensure that it's all working. For help, come to office hours or check out [this](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab) link (where we got the tensorboard-colab integration).\n",
        "\n",
        "**Important:** Note that we've changed the logging folder to \"./logs\" . Keep that in mind when using tensorboard."
      ]
    },
    {
      "metadata": {
        "id": "2btBOJ_gpmdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PyTorch Dataloaders **\n",
        "\n",
        "The first step to deep learning is to create a dataloader. It's important to understand how a dataloader works so you can create a custom dataloader for datasets in the future. To understand more, we highly recommend PyTorch's tutorial on dataloaders detailed [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "**Q2a (2 pts):** Create a training and testing dataloader for the Fashion-MNIST dataset. Report the size of the training and testing sets respectively (it should match those from the previous question.)\n",
        "\n",
        "*Hint:* Fashion-MNIST is a highly used dataset, therefore you do not have to create a whole dataloader from scratch. For some help, take a look at Torch's [dataset](https://pytorch.org/docs/stable/torchvision/datasets.html) and [dataloader](https://pytorch.org/docs/stable/data.html) page."
      ]
    },
    {
      "metadata": {
        "id": "JwU2URVvTy_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUPsp_iYp6HB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating the Neural Network Model**\n",
        "\n",
        "PyTorch has a fantastic tutorial on creating a neural network model, detailed [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
        "\n",
        "**Q2b (2 pts):** Using knowledge from lecture and the tutorial from the link above, create a neural network model to classify the Fashion-MNIST dataset. In your report, detail your network architecture, explaining the choices that you made (i.e. depth of the neural network, activation functions, etc).\n",
        "\n",
        "*NOTE:* You may **not** use convolutional layers in this model."
      ]
    },
    {
      "metadata": {
        "id": "V2GEI9xWUk0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcO78KpZqnc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating the Training Loop**\n",
        "\n",
        "**Q2c (2 pts):** Create a training loop that goes over the entire Fashion-MNIST dataset once. You should tune all hyperparameters (i.e. batch-size, learning rate, etc). Use tensorboard so that in one graph, plot accuracy vs iterations, and in the other plot loss vs iterations (axis labels are not needed if you're using tensorboard). Report the final testing accuracy and loss."
      ]
    },
    {
      "metadata": {
        "id": "BS1RH2Uhqn3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this object to help with tensorboard integration!\n",
        "from hw1.helper import Logger\n",
        "logger = Logger('./logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIXTJze5BU2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q2d (2 pts):** Create a testing loop that outputs the accuracy of your trained neural network on the test set. Report the evaluation accuracy of your network on this testing set.\n",
        "\n",
        "*Hint:* Look at the torch.no_grad() function to evaluate your neural network without updating the weights."
      ]
    },
    {
      "metadata": {
        "id": "aRBDCwCwsZn0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32ljCpPZVISV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q2e (2 pts):** Compare the testing accuracy of your neural network vs. the decision tree clasifier you made in the previous part."
      ]
    },
    {
      "metadata": {
        "id": "L_UJwNd6e_fy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 3. Deep Learning Diagnosis"
      ]
    },
    {
      "metadata": {
        "id": "8anIoyXm_KCm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.1.a MNIST control group (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "n1_Tpkid_Lpm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the same PyTorch approach as above, tune the hyperparameters for a neural net on the MNIST dataset.  Plot the learning curve and report its final accuracy in your writeup.  This neural net's performance will serve as the reference point (a \"control group\") for your analysis in parts 3.2, 3.4, and 3.7"
      ]
    },
    {
      "metadata": {
        "id": "gokRcC3S_F9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Tune hyperparameters here\n",
        "num_epochs = 5\n",
        "\n",
        "# Load the MNIST dataset (images and labels, both train and test) into 2 DataLoaders\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      # TODO: construct the submodules\n",
        "      return\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TODO: define the forward pass\n",
        "      return\n",
        "      \n",
        "# TODO: complete the train loop\n",
        "total_step = len(train_dataset)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataset):\n",
        "      pass\n",
        "    \n",
        "# TODO: complete the test loop\n",
        "\n",
        "# TODO: plot the learning curve."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_9ODXL2BTuA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.1.b CIFAR control group (10 pts)\n",
        "\n",
        "Similar to the previous part, create a neural network, training, and testing loop and tune the hyperparameters for the CIFAR-10 dataset. Plot the learning curve and report its final accuracy in your writeup.  This neural net's performance will serve as the reference point (a \"control group\") for your analysis in parts 3.3, 3.5, and 3.6"
      ]
    },
    {
      "metadata": {
        "id": "8ezAlVKNBVit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Tune hyperparameters here\n",
        "num_epochs = 5\n",
        "\n",
        "# Load the MNIST dataset (images and labels, both train and test) into 2 DataLoaders\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      # TODO: construct the submodules\n",
        "      return\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TODO: define the forward pass\n",
        "      return\n",
        "      \n",
        "# TODO: complete the train loop\n",
        "total_step = len(train_dataset)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataset):\n",
        "      pass\n",
        "    \n",
        "# TODO: complete the test loop\n",
        "\n",
        "# TODO: plot the learning curve."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvGlIFRfwDKY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each question below, we will provide 3 PyTorch objects: a DataLoader, a neural network model, and an optimizer (you will load them using dill, a serialization library in Python).  For each question, please complete the following:\n",
        "\n",
        "a.   Train the given neural net using the given DataLoader and the given optimizer.  Plot the learning curve of the network and report the final accuracy in your writeup.\n",
        "\n",
        "b.   Identify whether the neural net seems to be training correctly.  If not, debug the issue (e.g. printing parameters, gradients, outputs) and report your methodology in your writeup. In addition, we highly recommend checking out [this](https://docs.google.com/document/d/11R5IiLMjddIWM2csfjFBZ__Adu0sY0zuVhbS3_5lLBQ/edit?usp=sharing) google doc with information about common failure modes for training deep neural networks.\n",
        "\n",
        "c.   If you identify an issue with any of the 3 given objects, replace the buggy object with one of your own making.  Then retrain the neural net, plot the new learning curve, and report the improved accuracy in your writeup.  Note that in each of the following problems, exactly 1 object out of the DataLoader, the neural net, and the optimizer will be buggy.  You should not have to replace more than 1.\n",
        "\n",
        "Run the code snippet below for some necessary packages / setup."
      ]
    },
    {
      "metadata": {
        "id": "GhVgSR4moTFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import dill\n",
        "import torch.optim as optim\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pInKH8sNfKoG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.2 MNIST diagnosis 1 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "3UTDn_Vk-3GB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_2_data_loader = dill.load( open( \"q3_2_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_2_data_loader()\n",
        "q_3_2_net_loader = dill.load( open( \"q3_2_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_2_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V76qV4--fSXg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.3 CIFAR diagnosis 1 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "I5rswHIx1tqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_3_data_loader = dill.load( open( \"q3_3_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_3_data_loader()\n",
        "q_3_3_net_loader = dill.load( open( \"q3_3_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_3_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RcNBMPnAfT11",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.4 MNIST diagnosis 2 (10 pts)\n",
        "\n",
        "*Hint:* Look at the test accuracy"
      ]
    },
    {
      "metadata": {
        "id": "akcUBX4yrlif",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "DeYVw-FQieNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_4_data_loader = dill.load( open( \"q3_4_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_4_data_loader()\n",
        "q_3_4_net_loader = dill.load( open( \"q3_4_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_4_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2FqPQMhYw6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.5 CIFAR diagnosis 2 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "wPm-3cGFhGMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_5_data_loader = dill.load( open( \"q3_5_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_5_data_loader()\n",
        "q_3_5_net_loader = dill.load( open( \"q3_5_net.p\", \"rb\" ) )\n",
        "net,optimizer = q_3_5_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EpFqb3TT0L37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.6 CIFAR diagnosis 3 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "r5a5m0wy0v5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_6_data_loader = dill.load( open( \"q3_6_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_6_data_loader()\n",
        "q_3_6_net_loader = dill.load( open( \"q3_6_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_6_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dse7oiK7wPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q 3.7 MNIST diagnosis 3 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "7vA-AFXY0v_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_7_data_loader = dill.load( open( \"q3_7_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_7_data_loader()\n",
        "q_3_7_net_loader = dill.load( open( \"q3_7_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_7_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}