{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“HW1.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumpLusWu/CIS700/blob/master/%E2%80%9CHW1_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GK7XEDAs-aoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone Git (0 pts)"
      ]
    },
    {
      "metadata": {
        "id": "X0PN1qeC-Qu4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following to get the required files needed for this assignment. "
      ]
    },
    {
      "metadata": {
        "id": "6C1SLvlD7tzu",
        "colab_type": "code",
        "outputId": "8cf1b566-8795-4744-f5b6-9b4d35fdb70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cis700/hw1-release.git\n",
        "!mv hw1-release/dills/* .\n",
        "!mv hw1-release hw1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hw1-release'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 6), reused 23 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sSnTRxZdZLjB",
        "colab_type": "code",
        "outputId": "6736acc4-1438-4a31-aa3d-e118fd5373d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hw1\t       q3_3_loader.p  q3_4_net.p     q3_6_loader.p  q3_7_net.p\n",
            "q3_2_loader.p  q3_3_net.p     q3_5_loader.p  q3_6_net.p     sample_data\n",
            "q3_2_net.p     q3_4_loader.p  q3_5_net.p     q3_7_loader.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sin2bVyRSdP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classical vs. Deep Learning Approach\n"
      ]
    },
    {
      "metadata": {
        "id": "55fvftr2QDm-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 1. Using Decision Trees to Classify Fashion-MNIST (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "58yJGsmVSkMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Understanding the Dataset**\n",
        "\n",
        "The first step to machine learning is to understand the dataset that you're given. Therefore, familiarize yourself with the Fashion-MNIST dataset. We recommend reading the paper published about the dataset, which is detailed [here](https://arxiv.org/pdf/1708.07747.pdf).\n",
        "\n",
        "**Q1a (2 pts):** Explain at a high level what the dataset is (i.e. what are the specifications of the input data and associated labels)."
      ]
    },
    {
      "metadata": {
        "id": "SAbLhkoj-0rC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The input data comes from the pictures of fashion products and is preprocessed to have the same image size as the MINST dataset. It has ten different classes and is labeled using numbers."
      ]
    },
    {
      "metadata": {
        "id": "1jGrylNPlHxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the Data**\n",
        "\n",
        "Since there's no built in dataloader for Fashion-MNIST built into sci-kit learn, we've created a dataloader that you may use. The first code snippet is to the install [wget](https://pypi.org/project/wget/) and sets up the directory structure for your data to go in.\n",
        "\n",
        "In the second code snippet, we provide the function made by the authors of the fashion-MNIST dataset to extract the downloaded data.\n",
        "\n",
        "**Q1b (3 pts):** Fill in the load_datasets function such that it returns the training data, training labels, testing data, and testing labels. In your report, indicate the dimensions of the training set and the testing set respectively. "
      ]
    },
    {
      "metadata": {
        "id": "wawpPWtf0dtu",
        "colab_type": "code",
        "outputId": "87648ba7-7457-4f11-ccbf-52bf29c09f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!mkdir -p data/fashion"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mOBZr3rLTW46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import wget\n",
        "import pdb\n",
        "\n",
        "## Function provided by the creators of Fashion-MNIST to unpack and load their data\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MLQSFsdUfNA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fill in this method to load the Fashion-MNIST dataset\n",
        "def load_datasets():\n",
        "  base_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
        "  files = [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]\n",
        "  fashion_dir = \"data/fashion\"\n",
        "  import wget\n",
        "  base_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
        "  files = [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]\n",
        "  for i in range(4):\n",
        "    wget.download(base_URL+files[i], 'data/fashion') # download the compressed data file\n",
        "  train_images, train_labels =load_mnist('data/fashion', kind='train')\n",
        "  test_images, test_labels=  load_mnist('data/fashion', kind='t10k')\n",
        "  # Return the correct four variables\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrYD0bvhsnYY",
        "colab_type": "code",
        "outputId": "a06ff6e0-45bd-4d86-e969-c970896eb89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_labels\n",
        "     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 ... 3 0 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cguJWQUzsnCc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AlnqKnqBmCiB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating a Classical Classifier**\n",
        "\n",
        "**Q1c (5 pts):** Use logistic regression to classify the Fashion-MNIST dataset. Note that because this is not sped up by a GPU this may take a few minutes to run. In your report, plot the learning curve for train and validation accuracy and report the final classification accuracy.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fKhoD8PQ9fAV",
        "colab_type": "code",
        "outputId": "a0dd609b-0e81-442e-febf-46f71b01c627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
        "\n",
        "# Create an instance of Logistic Regression Classifier and fit the data.\n",
        "logreg.fit(train_images, train_labels)\n",
        "Z = logreg.predict(test_images)\n",
        "print (accuracy_score(test_labels, Z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WYdQXiEQ_Isy",
        "colab_type": "code",
        "outputId": "5b2fb650-fe96-420c-cfcf-0a8502cee558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print (accuracy_score(test_labels, Z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dmsoPT5Cmo7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 2. Using Deep Learning to Classify Fashion-MNIST (10 pts)\n",
        "\n",
        "In this section you will also classify the Fashion-MNIST dataset, however, with a deep neural network instead.\n",
        "\n",
        "**Downloading PyTorch**\n",
        "\n",
        "Run the code snippet below to install PyTorch / required packages and set up the GPU."
      ]
    },
    {
      "metadata": {
        "id": "R7YYE8Wm7aml",
        "colab_type": "code",
        "outputId": "3438895f-e502-4149-9eee-f9f3b0281e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "## Required packages\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image\n",
        "\n",
        "## Add any other packages you may need below"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.0rc2)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0rc0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (5.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o2EVPAWLR3W3",
        "colab_type": "code",
        "outputId": "d8e9fcb6-f172-43aa-cfd2-b5387b7490f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 614.8MB 26kB/s \n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-1.0.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M5dETVerGj_2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PyTorch Tensorboard Integration**\n",
        "\n",
        "In this class we present the option of using tensorboard to visualize loss / accuracy plots and images. You may choose to use matplotlib instead, however, we recommend using tensorboard as it's becoming the industry standard for analyzing / debugging neural networks. \n",
        "\n",
        "Simply run the code snippets below in the order provided, and click on the link to open up the tensorboard dashboard (which should be blank right now!)."
      ]
    },
    {
      "metadata": {
        "id": "7oiaJ44FDxmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwXtb51rtxe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ede58fcc-3676-4b4e-db3c-156b74fce64d"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: http://34c81d04.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZoJmRjNmF8HL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c842voLNGJdY",
        "colab_type": "code",
        "outputId": "28817539-1726-41aa-babf-7094befa0ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: http://34c81d04.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W7Vk-T2rEdfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this object to help with tensorboard integration!\n",
        "from hw1.helper import Logger\n",
        "import numpy as np\n",
        "# logger = Logger('./logs')\n",
        "# info = { 'loss': 5, 'accuracy': 6 }\n",
        "# step =0\n",
        "# c = np.arange(1000)\n",
        "# d = np.arange(2000,3000,1)\n",
        "# for i in range(1000):\n",
        "#         logger.scalar_summary('loss', d[i], step+1)\n",
        "#         step=step+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-G5XfE0HQFFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To see how to use Pytorch with tensorboard, check out [this](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/tensorboard/main.py) github repo (specifically in main.py). Try plotting something using tensorboard to ensure that it's all working. For help, come to office hours or check out [this](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab) link (where we got the tensorboard-colab integration).\n",
        "\n",
        "**Important:** Note that we've changed the logging folder to \"./logs\" . Keep that in mind when using tensorboard."
      ]
    },
    {
      "metadata": {
        "id": "2btBOJ_gpmdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PyTorch Dataloaders **\n",
        "\n",
        "The first step to deep learning is to create a dataloader. It's important to understand how a dataloader works so you can create a custom dataloader for datasets in the future. To understand more, we highly recommend PyTorch's tutorial on dataloaders detailed [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "**Q2a (2 pts):** Create a training and testing dataloader for the Fashion-MNIST dataset. Report the size of the training and testing sets respectively (it should match those from the previous question.)\n",
        "\n",
        "*Hint:* Fashion-MNIST is a highly used dataset, therefore you do not have to create a whole dataloader from scratch. For some help, take a look at Torch's [dataset](https://pytorch.org/docs/stable/torchvision/datasets.html) and [dataloader](https://pytorch.org/docs/stable/data.html) page."
      ]
    },
    {
      "metadata": {
        "id": "JwU2URVvTy_d",
        "colab_type": "code",
        "outputId": "4f79a77c-1e7e-41dc-d8de-3a984bd6f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "#import \n",
        "root = os.path.join('data','/fashion')\n",
        "print(root)\n",
        "fashion_train_dataset = torchvision.datasets.FashionMNIST(root, train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "fashion_test_dataset = torchvision.datasets.FashionMNIST(root, train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/fashion\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mUPsp_iYp6HB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating the Neural Network Model**\n",
        "\n",
        "PyTorch has a fantastic tutorial on creating a neural network model, detailed [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
        "\n",
        "**Q2b (2 pts):** Using knowledge from lecture and the tutorial from the link above, create a neural network model to classify the Fashion-MNIST dataset. In your report, detail your network architecture, explaining the choices that you made (i.e. depth of the neural network, activation functions, etc).\n",
        "\n",
        "*NOTE:* You may **not** use convolutional layers in this model."
      ]
    },
    {
      "metadata": {
        "id": "V2GEI9xWUk0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# fully connected neural network with one hidden layer\n",
        "class Net(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size,num_classes)\n",
        "    # need softmax?\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ph_gz1P5Ha-A",
        "colab_type": "code",
        "outputId": "29e4f830-b65a-478c-a1e8-150fb10a953a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nn =Net(28*28,500,10)\n",
        "params = list(nn.parameters())\n",
        "print(len(params ))  # 4 layer's weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mHtYE2PLIpje",
        "colab_type": "code",
        "outputId": "35f8a4bf-f154-4f8b-b166-be70ca8caafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "print(nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pcO78KpZqnc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating the Training Loop**\n",
        "\n",
        "**Q2c (2 pts):** Create a training loop that goes over the entire Fashion-MNIST dataset once. You should tune all hyperparameters (i.e. batch-size, learning rate, etc). Use tensorboard so that in one graph, plot accuracy vs iterations, and in the other plot loss vs iterations (axis labels are not needed if you're using tensorboard). Report the final testing accuracy and loss."
      ]
    },
    {
      "metadata": {
        "id": "UJdTTVCphQ5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r ./logs # clear the tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BS1RH2Uhqn3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time, datetime\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# fully connected neural network with one hidden layer\n",
        "class Net(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size,num_classes)\n",
        "    # need softmax?\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "# for debug use\n",
        "import pdb\n",
        "# Use this object to help with tensorboard integration!\n",
        "from hw1.helper import Logger\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{now}/')  # create different logger according time\n",
        "\n",
        "# hyper-parameters\n",
        "input_size = 28*28\n",
        "hidden_size  = 500\n",
        "num_classes = 10\n",
        "batch_size  = 128\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "# load data\n",
        "train_loader = torch.utils.data.DataLoader(fashion_train_dataset,batch_size = batch_size,shuffle =True)\n",
        "test_loader = torch.utils.data.DataLoader(fashion_test_dataset,batch_size = batch_size,shuffle =False)\n",
        "\n",
        "\n",
        "model  = Net(input_size, hidden_size,num_classes).to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step =  len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    # move tensors  to the configured device\n",
        "    \n",
        "     \n",
        "    #print(images.shape)\n",
        "    # images input 128*1*28*28\n",
        "    images = images.reshape(-1,28*28).to(device)  # 128*28*28\n",
        "    \n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "    \n",
        "    # backward and optimize\n",
        "    optimizer.zero_grad() # clear optimizer\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # compute accuracy\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    accuracy = (labels == argmax.squeeze()).float().mean()  # compare 128\n",
        "    info = { 'loss': loss.item(), 'accuracy': accuracy.item() } #  need to use item, accuracy is the tensor>tensor(0.0781, device='cuda:0')\n",
        "    # debug\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag, value, epoch+1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDythfGKmBFJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With softmax, why worse?"
      ]
    },
    {
      "metadata": {
        "id": "CIXTJze5BU2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q2d (2 pts):** Create a testing loop that outputs the accuracy of your trained neural network on the test set. Report the evaluation accuracy of your network on this testing set.\n",
        "\n",
        "*Hint:* Look at the torch.no_grad() function to evaluate your neural network without updating the weights."
      ]
    },
    {
      "metadata": {
        "id": "aRBDCwCwsZn0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "# don't need to compute gradients for memory efficiency\n",
        "with torch.no_grad(): \n",
        "  correct  = 0\n",
        "  total  = 0\n",
        "  for images,labels in test_loader:\n",
        "    images = images.reshape(-1,28*28).to(device) #why need one more dimension -1, because is the batch\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "   # pdb.set_trace()\n",
        "    _,predicted = torch.max(outputs.data,1) # outputs.data will output two tensor, one is prob ,one is label\n",
        "    total += labels.size(0) # size += 128\n",
        "    correct += (predicted == labels).sum().item()  #.sum().item():because .sum is still a tensor use .item to get rid of cuda\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "    \n",
        "# Save the model checkpoint\n",
        "#torch.save(model.state_dict(), 'model.ckpt')\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32ljCpPZVISV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q2e (2 pts):** Compare the testing accuracy of your neural network vs. the decision tree clasifier you made in the previous part."
      ]
    },
    {
      "metadata": {
        "id": "CDelNOxClt8h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The test accuracy is a bit of higher compared to logistic regression. 87% vs 84%."
      ]
    },
    {
      "metadata": {
        "id": "xKBVGqXyy52p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs/run_1551284730.0\n",
        "!rm -r logs/run_1551284785.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_UJwNd6e_fy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 3. Deep Learning Diagnosis"
      ]
    },
    {
      "metadata": {
        "id": "8anIoyXm_KCm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.1.a MNIST control group (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "n1_Tpkid_Lpm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the same PyTorch approach as above, tune the hyperparameters for a neural net on the MNIST dataset.  Plot the learning curve and report its final accuracy in your writeup.  This neural net's performance will serve as the reference point (a \"control group\") for your analysis in parts 3.2, 3.4, and 3.7"
      ]
    },
    {
      "metadata": {
        "id": "gokRcC3S_F9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time, datetime\n",
        "import pdb\n",
        "\n",
        "# Tune hyperparameters here\n",
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "hidden_layer = 256\n",
        "input_layer  =28*28\n",
        "classes = 10\n",
        "leaning_rate = 1e-3\n",
        "\n",
        "# Load the MNIST dataset (images and labels, both train and test) into 2 DataLoaders\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download = True)\n",
        "# load data\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle =True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size,shuffle =False)\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self,input_layer ,hidden_layer,classes):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1 = nn.Linear(input_layer ,hidden_layer)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_layer,classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      # TODO: define the forward pass\n",
        "      out = self.fc1(x)\n",
        "      out = self.relu(out)\n",
        "      out = self.fc2(out)\n",
        "      return out\n",
        "\n",
        "# logger for tensorboard\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{now}/')  # create different logger according time\n",
        "    \n",
        "# TODO: complete the train loop\n",
        "total_step = len(train_dataset)\n",
        "model =  Net(input_layer,hidden_layer,classes).to(device)\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      input_image  = images.reshape(-1,28*28).to(device)\n",
        "      \n",
        "      labels  = labels.to(device)\n",
        "     \n",
        "    # forward pass\n",
        "      outputs2 =  model(input_image)\n",
        "      loss = criterion(outputs2,labels)\n",
        "      \n",
        "    # backward pass and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    # accuracy\n",
        "      _, argmax = torch.max(outputs2,1)\n",
        "\n",
        "      # accuracy  = (labels == argmax).mean()\n",
        "      accuracy  = (labels == argmax.squeeze()).float().mean()\n",
        "      # learing curve\n",
        "      curve ={'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "      # add to summary\n",
        "      for tag,value in curve.items():\n",
        "        logger.scalar_summary(tag,value,i*(epoch+1)+1)\n",
        "   \n",
        "\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "    # TODO: plot the learning curve.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnD7M9Gy4cl-",
        "colab_type": "code",
        "outputId": "31f86a91-c5f0-43e0-a59f-435ee5bef49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: complete the test loop\n",
        "with torch.no_grad(): \n",
        "  correct  = 0\n",
        "  total  = 0\n",
        "  for images,labels in test_loader:\n",
        "    images = images.reshape(-1,28*28).to(device) #why need one more dimension -1, because is the batch\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        " \n",
        "   # pdb.set_trace()\n",
        "    _,predicted = torch.max(outputs.data,1) # outputs.data will output two tensor, one is prob ,one is label\n",
        "    total += labels.size(0) # size += 128\n",
        "    correct += (predicted == labels).sum().item()  #.sum().item():because .sum is still a tensor use .item to get rid of cuda\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "    \n",
        "# Save the model checkpoint\n",
        "#torch.save(model.state_dict(), 'model.ckpt')\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nZ1-BtEK4EJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train_loss:0.11 train_accuracy:96%"
      ]
    },
    {
      "metadata": {
        "id": "A_9ODXL2BTuA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.1.b CIFAR control group (10 pts)\n",
        "\n",
        "Similar to the previous part, create a neural network, training, and testing loop and tune the hyperparameters for the CIFAR-10 dataset. Plot the learning curve and report its final accuracy in your writeup.  This neural net's performance will serve as the reference point (a \"control group\") for your analysis in parts 3.3, 3.5, and 3.6"
      ]
    },
    {
      "metadata": {
        "id": "A3x_GbzI6CQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**First try: use CNN**"
      ]
    },
    {
      "metadata": {
        "id": "8ezAlVKNBVit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time, datetime\n",
        "# Tune hyperparameters here\n",
        "\n",
        "num_epochs = 80\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "# logger for tensorboard\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{now}/')  # create different logger according time\n",
        "\n",
        "# Load the MNIST dataset (images and labels, both train and test) into 2 DataLoaders\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=False)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# data_loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle =False)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes=10):\n",
        "      super(ConvNet, self).__init__()\n",
        "      self.layer1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.layer2 = nn.Sequential(\n",
        "          nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "      self.fc = nn.Linear(8*8*32, num_classes)  # 32/2/2 \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        #pdb.set_trace()\n",
        "        out = out.reshape(out.size(0), -1)  # out 128*32*8*8\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "model = ConvNet(num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# TODO: complete the train loop\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "step = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        \n",
        "        _, argmax = torch.max(outputs,1)\n",
        "        accuracy  = (labels == argmax.squeeze()).float().mean()  # the accuracy is the average of 128 images? or more\n",
        "      \n",
        "        info ={'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "        #pdb.set_trace()\n",
        "        step = step+1\n",
        "        logger.scalar_summary('loss',info['loss'],step)\n",
        "        logger.scalar_summary('accuracy',info['accuracy'],step)\n",
        "# TODO: complete the test loop\n",
        "# TODO: plot the learne."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrhxUCxaf0QK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klFWfzNqckVv",
        "colab_type": "code",
        "outputId": "a1cb2c2a-db00-45fb-d526-83abb7e2e310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "    # test in batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 83.346 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GvGlIFRfwDKY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each question below, we will provide 3 PyTorch objects: a DataLoader, a neural network model, and an optimizer (you will load them using dill, a serialization library in Python).  For each question, please complete the following:\n",
        "\n",
        "a.   Train the given neural net using the given DataLoader and the given optimizer.  Plot the learning curve of the network and report the final accuracy in your writeup.\n",
        "\n",
        "b.   Identify whether the neural net seems to be training correctly.  If not, debug the issue (e.g. printing parameters, gradients, outputs) and report your methodology in your writeup. In addition, we highly recommend checking out [this](https://docs.google.com/document/d/11R5IiLMjddIWM2csfjFBZ__Adu0sY0zuVhbS3_5lLBQ/edit?usp=sharing) google doc with information about common failure modes for training deep neural networks.\n",
        "\n",
        "c.   If you identify an issue with any of the 3 given objects, replace the buggy object with one of your own making.  Then retrain the neural net, plot the new learning curve, and report the improved accuracy in your writeup.  Note that in each of the following problems, exactly 1 object out of the DataLoader, the neural net, and the optimizer will be buggy.  You should not have to replace more than 1.\n",
        "\n",
        "Run the code snippet below for some necessary packages / setup."
      ]
    },
    {
      "metadata": {
        "id": "6AtDkFX4eluk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dill\n",
        "import torch.optim as optim\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pInKH8sNfKoG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.2 MNIST diagnosis 1 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "5aUSFCIOh_Ae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_2_data_loader = dill.load( open( \"q3_2_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_2_data_loader()\n",
        "q_3_2_net_loader = dill.load( open( \"q3_2_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_2_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ffvX6wlbogQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cda5d87-182c-48fc-cf8c-e090e58759e9"
      },
      "cell_type": "code",
      "source": [
        "print(train_loader.batch_size)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "THiX0Z-UitPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the tensorboard, it seems that the network was initailzed with zero mean and zero weight"
      ]
    },
    {
      "metadata": {
        "id": "8t-Qz_awl5y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f2e20684-4d35-4067-b068-c59034f87cfa"
      },
      "cell_type": "code",
      "source": [
        "print(optimizer)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0003\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w-mRPE5VxMOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "54d53967-7017-4f8b-e29a-de653c593626"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{now}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "# problem fix\n",
        "torch.nn.init.xavier_uniform(net.fc1.weight)\n",
        "torch.nn.init.xavier_uniform(net.fc2.weight)\n",
        "torch.nn.init.xavier_uniform(net.fc3.weight)\n",
        "torch.nn.init.xavier_uniform(net.fc4.weight)\n",
        "torch.nn.init.xavier_uniform(net.fc5.weight)\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #pdb.set_trace()\n",
        "    #forward pass\n",
        "   \n",
        "    #pdb.set_trace()\n",
        "    outputs  = model(images)\n",
        "    #pdb.set_trace()\n",
        "    loss  = criterion(outputs,labels) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    #pdb.set_trace()\n",
        "    loss.backward()\n",
        "    #pdb.set_trace()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag,value,step)\n",
        "      # 2. Log values and gradients of the parameters (histogram summary)\n",
        "    for tag, value in model.named_parameters():\n",
        "        tag = tag.replace('.', '/')\n",
        "        logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "\n",
        "    # 3. Log training images (image summary)\n",
        "    info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
        "\n",
        "    for tag, images in info.items():\n",
        "        logger.image_summary(tag, images, step)\n",
        "    if step %100 ==0:\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      \n",
        "    \n",
        "   \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.9699999690055847\n",
            "accuracy:0.9799999594688416\n",
            "accuracy:1.0\n",
            "accuracy:1.0\n",
            "accuracy:1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3UTDn_Vk-3GB",
        "colab_type": "code",
        "outputId": "c5834d2c-7c06-432c-812f-2272f62bdd35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.1084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ixLrZpvUf1Au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V76qV4--fSXg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.3 CIFAR diagnosis 1 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "X9iqjOyifrZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Diagnositic: It seems that the train data is not shuffled. To fix it, I shuffle the dataset.**"
      ]
    },
    {
      "metadata": {
        "id": "Gv5uezj8uPhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b993b21e-b170-401c-b4b2-68f4bf49891e"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: https://3c4c45c7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gVqpl5Zvf0hp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "I5rswHIx1tqy",
        "colab_type": "code",
        "outputId": "9a3320ac-6b35-4c1e-b452-02c1c52f609e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "q_3_3_data_loader = dill.load( open( \"q3_3_loader.p\", \"rb\" ) )\n",
        "train_loader2, test_loader2 = q_3_3_data_loader()\n",
        "q_3_3_net_loader = dill.load( open( \"q3_3_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_3_net_loader()\n"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yS0VmaGwaYx6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_loader2.dataset,\n",
        "                                          batch_size = train_loader2.batch_size,\n",
        "                                          shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=train_loader2.dataset,\n",
        "                                          batch_size = train_loader2.batch_size,\n",
        "                                          shuffle =False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4G24HAOqh-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7100
        },
        "outputId": "3cbd139d-41fd-4b0e-8627-e6ac630f02ad"
      },
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "\n",
        "\n",
        "for images, labels in train_loader:\n",
        " # pdb.set_trace()\n",
        "  count= []\n",
        "  for i in range(10):\n",
        "    count.append(sum(labels==i).item())\n",
        "    \n",
        "  print(count)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 8, 12, 10, 7, 10, 10, 9, 15, 9]\n",
            "[10, 6, 9, 13, 14, 11, 9, 8, 13, 7]\n",
            "[6, 12, 12, 14, 11, 9, 11, 6, 10, 9]\n",
            "[13, 9, 7, 9, 10, 12, 12, 15, 2, 11]\n",
            "[11, 12, 13, 6, 8, 11, 13, 7, 13, 6]\n",
            "[12, 8, 9, 18, 11, 8, 4, 10, 9, 11]\n",
            "[6, 11, 15, 11, 11, 9, 10, 9, 12, 6]\n",
            "[11, 13, 9, 12, 13, 11, 2, 7, 12, 10]\n",
            "[9, 14, 8, 10, 7, 12, 13, 10, 10, 7]\n",
            "[7, 8, 8, 9, 14, 12, 11, 10, 7, 14]\n",
            "[8, 11, 8, 12, 7, 9, 19, 6, 6, 14]\n",
            "[15, 12, 7, 11, 11, 10, 8, 11, 10, 5]\n",
            "[6, 15, 9, 8, 10, 12, 10, 5, 16, 9]\n",
            "[18, 9, 5, 12, 11, 7, 11, 6, 9, 12]\n",
            "[4, 8, 14, 5, 11, 10, 12, 14, 13, 9]\n",
            "[20, 8, 11, 12, 5, 12, 7, 13, 8, 4]\n",
            "[11, 7, 18, 8, 8, 13, 11, 9, 5, 10]\n",
            "[10, 13, 14, 6, 5, 11, 13, 8, 8, 12]\n",
            "[9, 8, 14, 12, 10, 11, 10, 4, 11, 11]\n",
            "[13, 10, 6, 11, 13, 10, 8, 9, 14, 6]\n",
            "[15, 9, 7, 7, 10, 9, 11, 12, 13, 7]\n",
            "[11, 7, 13, 8, 9, 10, 13, 13, 6, 10]\n",
            "[10, 5, 11, 6, 15, 14, 10, 9, 10, 10]\n",
            "[4, 8, 10, 11, 7, 14, 14, 14, 7, 11]\n",
            "[12, 11, 11, 11, 5, 12, 9, 8, 14, 7]\n",
            "[14, 5, 7, 10, 11, 6, 14, 8, 20, 5]\n",
            "[3, 12, 11, 8, 8, 7, 10, 14, 18, 9]\n",
            "[9, 13, 14, 10, 13, 7, 7, 9, 5, 13]\n",
            "[11, 10, 13, 5, 11, 13, 9, 9, 10, 9]\n",
            "[9, 11, 12, 12, 6, 10, 9, 7, 12, 12]\n",
            "[10, 13, 11, 8, 10, 13, 5, 9, 12, 9]\n",
            "[8, 9, 7, 9, 15, 11, 14, 10, 10, 7]\n",
            "[12, 12, 6, 10, 11, 11, 9, 8, 7, 14]\n",
            "[12, 8, 8, 8, 10, 14, 9, 8, 7, 16]\n",
            "[17, 11, 4, 12, 10, 11, 5, 10, 10, 10]\n",
            "[14, 7, 17, 13, 6, 8, 10, 10, 9, 6]\n",
            "[15, 11, 6, 9, 5, 9, 7, 13, 14, 11]\n",
            "[6, 12, 15, 12, 7, 12, 9, 10, 12, 5]\n",
            "[7, 13, 6, 15, 6, 12, 9, 13, 13, 6]\n",
            "[8, 8, 9, 6, 17, 11, 11, 8, 11, 11]\n",
            "[10, 13, 15, 13, 9, 5, 5, 9, 9, 12]\n",
            "[17, 4, 7, 8, 9, 9, 5, 15, 14, 12]\n",
            "[12, 8, 8, 5, 10, 9, 12, 12, 8, 16]\n",
            "[7, 11, 10, 9, 8, 20, 5, 12, 6, 12]\n",
            "[5, 12, 9, 13, 11, 13, 6, 16, 8, 7]\n",
            "[9, 12, 12, 5, 8, 8, 9, 14, 7, 16]\n",
            "[6, 8, 9, 10, 11, 13, 11, 9, 11, 12]\n",
            "[6, 11, 6, 11, 18, 12, 10, 8, 8, 10]\n",
            "[9, 11, 11, 11, 8, 5, 13, 9, 9, 14]\n",
            "[10, 9, 11, 8, 6, 10, 15, 7, 14, 10]\n",
            "[10, 8, 12, 13, 12, 10, 3, 10, 11, 11]\n",
            "[9, 8, 13, 12, 8, 8, 10, 13, 9, 10]\n",
            "[13, 7, 7, 11, 9, 9, 14, 11, 10, 9]\n",
            "[14, 5, 11, 11, 10, 9, 12, 14, 5, 9]\n",
            "[14, 10, 14, 10, 12, 9, 8, 7, 8, 8]\n",
            "[9, 14, 9, 10, 16, 6, 9, 5, 11, 11]\n",
            "[9, 13, 11, 13, 8, 7, 12, 11, 5, 11]\n",
            "[13, 11, 9, 15, 7, 9, 11, 11, 6, 8]\n",
            "[11, 6, 9, 9, 9, 13, 13, 8, 11, 11]\n",
            "[15, 9, 16, 9, 11, 7, 14, 11, 5, 3]\n",
            "[16, 9, 5, 8, 6, 13, 12, 11, 12, 8]\n",
            "[10, 8, 12, 5, 11, 5, 14, 11, 12, 12]\n",
            "[7, 7, 11, 9, 12, 19, 5, 9, 10, 11]\n",
            "[14, 9, 4, 15, 8, 7, 11, 10, 12, 10]\n",
            "[8, 9, 7, 11, 13, 15, 5, 8, 15, 9]\n",
            "[4, 11, 9, 9, 5, 17, 12, 10, 10, 13]\n",
            "[9, 13, 7, 7, 5, 11, 8, 19, 12, 9]\n",
            "[7, 8, 10, 10, 17, 11, 10, 11, 7, 9]\n",
            "[8, 8, 15, 11, 10, 7, 12, 12, 9, 8]\n",
            "[6, 7, 11, 14, 15, 14, 9, 11, 7, 6]\n",
            "[15, 9, 7, 12, 9, 9, 9, 18, 6, 6]\n",
            "[11, 8, 6, 13, 16, 10, 4, 12, 8, 12]\n",
            "[9, 14, 7, 8, 14, 11, 10, 11, 8, 8]\n",
            "[7, 13, 7, 12, 5, 11, 12, 10, 14, 9]\n",
            "[6, 10, 11, 8, 15, 13, 10, 13, 7, 7]\n",
            "[12, 12, 6, 13, 11, 3, 8, 9, 14, 12]\n",
            "[3, 12, 12, 4, 13, 10, 15, 10, 9, 12]\n",
            "[7, 11, 10, 11, 15, 6, 9, 10, 13, 8]\n",
            "[7, 8, 13, 10, 6, 18, 12, 11, 7, 8]\n",
            "[6, 9, 9, 6, 10, 7, 12, 13, 11, 17]\n",
            "[8, 8, 6, 10, 8, 12, 11, 13, 14, 10]\n",
            "[11, 10, 9, 8, 14, 8, 8, 7, 16, 9]\n",
            "[8, 15, 8, 11, 2, 15, 15, 7, 10, 9]\n",
            "[7, 8, 12, 10, 9, 8, 8, 14, 10, 14]\n",
            "[15, 9, 14, 9, 7, 10, 13, 4, 7, 12]\n",
            "[12, 8, 11, 7, 10, 15, 12, 6, 11, 8]\n",
            "[9, 10, 9, 12, 9, 7, 15, 11, 11, 7]\n",
            "[9, 9, 8, 9, 6, 9, 11, 11, 16, 12]\n",
            "[10, 6, 12, 4, 14, 9, 12, 10, 15, 8]\n",
            "[11, 11, 12, 8, 8, 16, 7, 8, 11, 8]\n",
            "[8, 13, 14, 10, 12, 9, 9, 5, 7, 13]\n",
            "[6, 14, 4, 11, 4, 10, 8, 20, 11, 12]\n",
            "[9, 15, 11, 8, 13, 7, 8, 16, 7, 6]\n",
            "[10, 10, 12, 13, 6, 8, 12, 9, 8, 12]\n",
            "[13, 9, 14, 14, 6, 10, 8, 7, 11, 8]\n",
            "[11, 6, 18, 5, 13, 11, 4, 14, 10, 8]\n",
            "[12, 12, 15, 6, 5, 10, 14, 10, 8, 8]\n",
            "[9, 10, 15, 8, 13, 10, 11, 12, 6, 6]\n",
            "[8, 9, 17, 10, 3, 10, 17, 6, 9, 11]\n",
            "[9, 10, 11, 13, 10, 13, 7, 10, 7, 10]\n",
            "[5, 7, 11, 9, 11, 9, 13, 13, 10, 12]\n",
            "[9, 7, 8, 10, 11, 9, 12, 12, 6, 16]\n",
            "[6, 13, 9, 6, 12, 12, 14, 8, 7, 13]\n",
            "[15, 7, 12, 10, 9, 10, 7, 9, 11, 10]\n",
            "[10, 7, 10, 12, 13, 6, 11, 9, 14, 8]\n",
            "[11, 14, 11, 5, 9, 10, 11, 13, 8, 8]\n",
            "[15, 7, 10, 12, 9, 7, 8, 13, 13, 6]\n",
            "[11, 9, 10, 11, 9, 12, 13, 9, 6, 10]\n",
            "[10, 10, 6, 12, 11, 14, 10, 13, 10, 4]\n",
            "[14, 18, 16, 8, 8, 5, 7, 6, 11, 7]\n",
            "[7, 6, 10, 11, 10, 9, 8, 11, 11, 17]\n",
            "[7, 13, 9, 13, 11, 14, 13, 4, 9, 7]\n",
            "[12, 9, 8, 15, 7, 9, 11, 13, 10, 6]\n",
            "[8, 12, 6, 11, 13, 9, 9, 11, 12, 9]\n",
            "[8, 13, 8, 7, 15, 14, 5, 11, 8, 11]\n",
            "[7, 8, 15, 10, 9, 12, 8, 17, 10, 4]\n",
            "[5, 9, 6, 8, 12, 6, 11, 14, 19, 10]\n",
            "[7, 10, 12, 11, 7, 6, 12, 17, 8, 10]\n",
            "[16, 10, 6, 9, 8, 5, 13, 9, 12, 12]\n",
            "[8, 9, 16, 14, 6, 9, 7, 12, 5, 14]\n",
            "[7, 11, 11, 9, 11, 6, 11, 8, 14, 12]\n",
            "[7, 12, 17, 7, 9, 11, 9, 10, 10, 8]\n",
            "[6, 12, 12, 9, 5, 14, 9, 8, 10, 15]\n",
            "[6, 4, 7, 11, 12, 9, 4, 16, 14, 17]\n",
            "[11, 8, 9, 11, 5, 10, 12, 13, 15, 6]\n",
            "[9, 10, 12, 12, 11, 8, 7, 14, 9, 8]\n",
            "[5, 11, 7, 16, 8, 12, 6, 11, 12, 12]\n",
            "[9, 9, 8, 7, 15, 8, 9, 13, 11, 11]\n",
            "[9, 11, 10, 9, 6, 12, 11, 11, 10, 11]\n",
            "[14, 9, 9, 8, 8, 14, 12, 7, 10, 9]\n",
            "[9, 9, 12, 11, 8, 10, 12, 12, 11, 6]\n",
            "[9, 12, 11, 9, 9, 10, 15, 6, 6, 13]\n",
            "[11, 8, 9, 10, 8, 7, 15, 9, 9, 14]\n",
            "[13, 8, 12, 8, 8, 11, 7, 9, 11, 13]\n",
            "[10, 14, 10, 13, 10, 16, 9, 6, 6, 6]\n",
            "[13, 4, 11, 10, 7, 18, 4, 12, 9, 12]\n",
            "[9, 8, 14, 10, 13, 3, 10, 17, 8, 8]\n",
            "[8, 7, 11, 8, 12, 12, 15, 8, 9, 10]\n",
            "[12, 11, 10, 9, 13, 12, 8, 9, 5, 11]\n",
            "[12, 12, 9, 10, 11, 7, 12, 14, 6, 7]\n",
            "[10, 10, 6, 11, 11, 7, 11, 12, 11, 11]\n",
            "[11, 12, 12, 11, 5, 10, 16, 8, 8, 7]\n",
            "[15, 8, 4, 13, 15, 11, 8, 12, 6, 8]\n",
            "[8, 11, 11, 10, 13, 11, 7, 11, 7, 11]\n",
            "[11, 6, 12, 8, 8, 8, 13, 8, 11, 15]\n",
            "[11, 10, 10, 5, 12, 13, 11, 11, 8, 9]\n",
            "[9, 13, 7, 10, 5, 6, 14, 5, 17, 14]\n",
            "[7, 18, 7, 9, 14, 8, 11, 8, 11, 7]\n",
            "[8, 7, 10, 11, 12, 16, 11, 8, 8, 9]\n",
            "[11, 10, 18, 9, 11, 10, 11, 6, 6, 8]\n",
            "[8, 11, 16, 7, 8, 6, 13, 12, 12, 7]\n",
            "[5, 6, 15, 11, 15, 5, 11, 7, 13, 12]\n",
            "[8, 14, 9, 8, 14, 10, 8, 5, 12, 12]\n",
            "[7, 8, 9, 8, 12, 12, 11, 14, 8, 11]\n",
            "[12, 9, 8, 9, 11, 10, 10, 12, 7, 12]\n",
            "[8, 9, 11, 9, 11, 12, 6, 11, 12, 11]\n",
            "[8, 11, 9, 8, 13, 12, 5, 13, 14, 7]\n",
            "[12, 9, 6, 7, 19, 13, 6, 11, 10, 7]\n",
            "[12, 13, 13, 7, 13, 9, 7, 5, 9, 12]\n",
            "[9, 8, 7, 10, 16, 11, 9, 8, 11, 11]\n",
            "[15, 6, 8, 11, 5, 11, 9, 10, 15, 10]\n",
            "[7, 6, 10, 11, 17, 7, 12, 9, 9, 12]\n",
            "[7, 7, 15, 9, 10, 12, 13, 12, 4, 11]\n",
            "[10, 9, 12, 9, 12, 16, 3, 12, 10, 7]\n",
            "[13, 10, 11, 11, 8, 12, 8, 9, 7, 11]\n",
            "[10, 14, 11, 8, 10, 9, 16, 6, 11, 5]\n",
            "[16, 9, 10, 13, 9, 7, 4, 12, 11, 9]\n",
            "[12, 9, 17, 6, 10, 5, 8, 10, 13, 10]\n",
            "[8, 12, 7, 17, 6, 10, 10, 9, 9, 12]\n",
            "[5, 10, 8, 5, 9, 14, 13, 12, 12, 12]\n",
            "[15, 11, 13, 9, 9, 5, 8, 9, 8, 13]\n",
            "[8, 8, 11, 10, 13, 5, 11, 13, 12, 9]\n",
            "[9, 7, 12, 11, 13, 9, 11, 12, 9, 7]\n",
            "[9, 10, 9, 6, 9, 12, 11, 10, 12, 12]\n",
            "[12, 4, 10, 9, 9, 13, 7, 9, 17, 10]\n",
            "[14, 7, 12, 9, 7, 10, 12, 9, 8, 12]\n",
            "[8, 14, 14, 10, 9, 7, 13, 6, 7, 12]\n",
            "[14, 11, 5, 11, 13, 10, 8, 14, 5, 9]\n",
            "[12, 19, 5, 7, 7, 9, 13, 7, 10, 11]\n",
            "[8, 7, 16, 6, 7, 13, 13, 7, 11, 12]\n",
            "[11, 7, 5, 7, 12, 10, 13, 10, 18, 7]\n",
            "[8, 14, 14, 13, 17, 5, 7, 9, 10, 3]\n",
            "[10, 5, 12, 6, 11, 11, 16, 8, 14, 7]\n",
            "[5, 8, 8, 10, 11, 15, 12, 9, 13, 9]\n",
            "[11, 16, 9, 6, 8, 12, 11, 7, 6, 14]\n",
            "[13, 6, 10, 8, 10, 12, 11, 10, 6, 14]\n",
            "[7, 7, 14, 14, 14, 7, 15, 10, 7, 5]\n",
            "[10, 5, 13, 11, 8, 10, 6, 12, 11, 14]\n",
            "[12, 11, 16, 6, 7, 9, 13, 8, 11, 7]\n",
            "[9, 9, 8, 11, 9, 14, 11, 8, 7, 14]\n",
            "[12, 10, 10, 15, 9, 11, 12, 7, 10, 4]\n",
            "[8, 12, 15, 13, 11, 10, 13, 2, 9, 7]\n",
            "[5, 16, 6, 14, 10, 15, 11, 4, 12, 7]\n",
            "[10, 14, 7, 8, 10, 6, 12, 9, 8, 16]\n",
            "[17, 6, 9, 6, 14, 6, 14, 14, 7, 7]\n",
            "[12, 14, 8, 11, 12, 11, 5, 6, 10, 11]\n",
            "[10, 9, 11, 10, 10, 12, 10, 6, 12, 10]\n",
            "[12, 14, 10, 12, 9, 8, 11, 8, 7, 9]\n",
            "[8, 13, 11, 13, 6, 9, 16, 12, 7, 5]\n",
            "[11, 10, 10, 11, 8, 9, 9, 10, 16, 6]\n",
            "[10, 6, 7, 15, 8, 11, 10, 14, 13, 6]\n",
            "[13, 9, 9, 10, 11, 10, 15, 4, 12, 7]\n",
            "[11, 15, 9, 8, 7, 4, 9, 11, 10, 16]\n",
            "[8, 6, 15, 10, 11, 13, 12, 10, 7, 8]\n",
            "[10, 5, 13, 10, 15, 13, 6, 7, 9, 12]\n",
            "[10, 13, 14, 12, 2, 12, 7, 9, 8, 13]\n",
            "[5, 10, 11, 14, 7, 13, 10, 10, 11, 9]\n",
            "[12, 9, 7, 14, 7, 8, 12, 9, 14, 8]\n",
            "[14, 9, 7, 11, 10, 8, 10, 9, 14, 8]\n",
            "[5, 6, 14, 12, 15, 10, 11, 7, 6, 14]\n",
            "[13, 11, 7, 11, 11, 7, 10, 8, 11, 11]\n",
            "[8, 10, 9, 9, 13, 10, 10, 11, 10, 10]\n",
            "[12, 16, 8, 11, 6, 9, 15, 9, 7, 7]\n",
            "[9, 12, 8, 9, 12, 11, 10, 12, 14, 3]\n",
            "[8, 8, 9, 10, 11, 13, 11, 10, 11, 9]\n",
            "[7, 12, 9, 6, 9, 10, 13, 12, 9, 13]\n",
            "[10, 6, 10, 9, 11, 10, 11, 10, 10, 13]\n",
            "[8, 11, 13, 13, 12, 11, 7, 8, 10, 7]\n",
            "[12, 11, 6, 10, 13, 10, 11, 7, 9, 11]\n",
            "[10, 11, 6, 8, 8, 13, 11, 8, 12, 13]\n",
            "[10, 13, 9, 9, 9, 8, 10, 20, 6, 6]\n",
            "[10, 10, 10, 11, 10, 9, 10, 11, 15, 4]\n",
            "[10, 12, 4, 7, 13, 11, 8, 12, 15, 8]\n",
            "[13, 8, 9, 10, 13, 10, 7, 11, 9, 10]\n",
            "[8, 12, 10, 6, 9, 8, 8, 12, 13, 14]\n",
            "[11, 8, 13, 11, 9, 8, 10, 13, 13, 4]\n",
            "[9, 8, 9, 9, 11, 12, 8, 20, 6, 8]\n",
            "[15, 10, 7, 11, 8, 10, 7, 8, 10, 14]\n",
            "[9, 11, 16, 7, 11, 6, 13, 6, 9, 12]\n",
            "[10, 16, 9, 11, 8, 7, 10, 8, 10, 11]\n",
            "[3, 8, 8, 7, 16, 14, 10, 11, 10, 13]\n",
            "[10, 8, 7, 8, 10, 9, 19, 8, 9, 12]\n",
            "[10, 10, 14, 9, 8, 9, 12, 7, 12, 9]\n",
            "[9, 9, 8, 10, 7, 9, 8, 12, 11, 17]\n",
            "[14, 13, 8, 11, 10, 12, 9, 6, 9, 8]\n",
            "[12, 10, 9, 8, 8, 12, 8, 15, 14, 4]\n",
            "[10, 8, 8, 12, 12, 13, 5, 9, 13, 10]\n",
            "[9, 8, 10, 18, 8, 11, 10, 9, 7, 10]\n",
            "[5, 12, 11, 12, 7, 3, 13, 15, 12, 10]\n",
            "[8, 13, 8, 8, 8, 11, 14, 6, 13, 11]\n",
            "[13, 7, 13, 4, 13, 7, 9, 10, 9, 15]\n",
            "[8, 8, 13, 13, 11, 10, 12, 9, 7, 9]\n",
            "[11, 4, 16, 6, 6, 13, 11, 12, 12, 9]\n",
            "[7, 14, 12, 14, 12, 4, 5, 12, 9, 11]\n",
            "[10, 10, 8, 14, 10, 9, 6, 11, 10, 12]\n",
            "[12, 12, 4, 10, 12, 13, 7, 11, 11, 8]\n",
            "[8, 11, 9, 11, 11, 7, 8, 8, 15, 12]\n",
            "[9, 11, 12, 13, 7, 5, 12, 10, 11, 10]\n",
            "[10, 11, 5, 18, 6, 8, 6, 8, 11, 17]\n",
            "[7, 8, 20, 10, 8, 13, 10, 9, 8, 7]\n",
            "[9, 7, 12, 9, 10, 11, 12, 10, 10, 10]\n",
            "[11, 10, 9, 10, 13, 6, 14, 8, 10, 9]\n",
            "[7, 11, 11, 11, 7, 11, 7, 9, 11, 15]\n",
            "[9, 9, 6, 15, 8, 11, 11, 7, 10, 14]\n",
            "[10, 13, 9, 9, 12, 6, 6, 10, 11, 14]\n",
            "[12, 6, 7, 12, 17, 8, 13, 11, 8, 6]\n",
            "[12, 10, 11, 11, 10, 11, 9, 9, 7, 10]\n",
            "[12, 11, 10, 10, 9, 12, 7, 8, 6, 15]\n",
            "[8, 9, 11, 8, 9, 10, 10, 11, 12, 12]\n",
            "[8, 12, 12, 17, 8, 10, 5, 8, 9, 11]\n",
            "[5, 13, 7, 11, 8, 15, 10, 10, 11, 10]\n",
            "[11, 13, 9, 10, 8, 12, 9, 12, 6, 10]\n",
            "[6, 10, 6, 12, 10, 15, 11, 8, 13, 9]\n",
            "[13, 13, 12, 11, 8, 8, 5, 10, 14, 6]\n",
            "[10, 9, 10, 12, 10, 9, 11, 8, 10, 11]\n",
            "[7, 13, 9, 15, 15, 6, 12, 4, 11, 8]\n",
            "[9, 8, 10, 16, 7, 9, 13, 9, 8, 11]\n",
            "[5, 9, 12, 13, 6, 15, 11, 9, 11, 9]\n",
            "[8, 18, 9, 7, 7, 6, 11, 8, 15, 11]\n",
            "[13, 10, 7, 16, 13, 10, 13, 7, 5, 6]\n",
            "[6, 8, 14, 8, 21, 6, 7, 10, 16, 4]\n",
            "[11, 7, 10, 8, 14, 6, 14, 6, 16, 8]\n",
            "[8, 8, 14, 12, 15, 9, 4, 9, 7, 14]\n",
            "[10, 10, 7, 13, 8, 10, 11, 10, 9, 12]\n",
            "[12, 12, 12, 10, 11, 11, 4, 10, 11, 7]\n",
            "[9, 10, 8, 7, 12, 10, 17, 8, 6, 13]\n",
            "[14, 8, 15, 8, 9, 5, 8, 11, 9, 13]\n",
            "[9, 10, 13, 6, 10, 6, 9, 12, 14, 11]\n",
            "[5, 11, 13, 14, 8, 5, 9, 12, 13, 10]\n",
            "[9, 13, 4, 11, 5, 17, 11, 15, 9, 6]\n",
            "[7, 11, 7, 9, 14, 9, 13, 9, 12, 9]\n",
            "[7, 12, 10, 8, 7, 15, 8, 10, 10, 13]\n",
            "[14, 5, 6, 13, 5, 18, 8, 9, 13, 9]\n",
            "[12, 12, 16, 4, 4, 14, 13, 7, 7, 11]\n",
            "[11, 10, 12, 6, 9, 10, 9, 13, 7, 13]\n",
            "[11, 9, 8, 10, 6, 11, 13, 16, 5, 11]\n",
            "[12, 6, 15, 16, 12, 8, 5, 12, 8, 6]\n",
            "[11, 6, 8, 8, 12, 12, 16, 9, 10, 8]\n",
            "[13, 11, 9, 8, 12, 9, 9, 11, 4, 14]\n",
            "[9, 9, 10, 10, 9, 13, 10, 10, 8, 12]\n",
            "[10, 10, 15, 19, 9, 12, 6, 8, 8, 3]\n",
            "[10, 8, 15, 10, 10, 11, 9, 11, 3, 13]\n",
            "[18, 9, 15, 8, 4, 10, 8, 7, 12, 9]\n",
            "[13, 14, 5, 6, 12, 13, 7, 6, 14, 10]\n",
            "[13, 5, 12, 14, 6, 11, 13, 8, 11, 7]\n",
            "[11, 5, 6, 10, 12, 10, 7, 15, 14, 10]\n",
            "[12, 13, 12, 6, 10, 7, 11, 10, 8, 11]\n",
            "[13, 9, 11, 12, 9, 8, 11, 13, 7, 7]\n",
            "[13, 9, 7, 16, 6, 2, 13, 14, 12, 8]\n",
            "[8, 12, 11, 8, 9, 14, 10, 7, 11, 10]\n",
            "[18, 8, 9, 8, 8, 12, 7, 7, 10, 13]\n",
            "[6, 10, 9, 7, 12, 13, 9, 7, 15, 12]\n",
            "[14, 13, 17, 9, 11, 7, 8, 10, 7, 4]\n",
            "[10, 11, 7, 13, 6, 12, 8, 11, 13, 9]\n",
            "[12, 15, 9, 5, 13, 13, 11, 6, 12, 4]\n",
            "[12, 7, 9, 6, 15, 7, 8, 10, 10, 16]\n",
            "[7, 11, 8, 15, 14, 7, 11, 9, 5, 13]\n",
            "[9, 16, 12, 6, 9, 13, 9, 7, 11, 8]\n",
            "[17, 6, 8, 7, 19, 4, 10, 11, 9, 9]\n",
            "[13, 6, 14, 12, 11, 10, 5, 7, 13, 9]\n",
            "[10, 18, 8, 12, 12, 11, 7, 8, 7, 7]\n",
            "[4, 7, 12, 10, 8, 16, 13, 14, 10, 6]\n",
            "[17, 6, 11, 9, 17, 11, 11, 6, 7, 5]\n",
            "[8, 12, 8, 10, 9, 9, 12, 12, 10, 10]\n",
            "[9, 16, 10, 9, 11, 3, 9, 12, 9, 12]\n",
            "[12, 13, 8, 10, 8, 9, 12, 9, 6, 13]\n",
            "[9, 10, 9, 13, 9, 12, 12, 12, 8, 6]\n",
            "[4, 7, 7, 14, 14, 10, 6, 13, 17, 8]\n",
            "[10, 14, 10, 13, 7, 5, 9, 11, 10, 11]\n",
            "[10, 5, 11, 8, 7, 5, 10, 16, 9, 19]\n",
            "[12, 11, 12, 5, 6, 9, 7, 13, 14, 11]\n",
            "[10, 12, 6, 10, 11, 8, 14, 9, 10, 10]\n",
            "[7, 7, 13, 5, 8, 13, 10, 14, 8, 15]\n",
            "[17, 14, 7, 9, 8, 8, 8, 9, 9, 11]\n",
            "[15, 15, 7, 12, 11, 7, 7, 10, 6, 10]\n",
            "[7, 16, 10, 13, 12, 6, 13, 7, 6, 10]\n",
            "[6, 11, 10, 11, 10, 8, 9, 9, 13, 13]\n",
            "[10, 13, 10, 11, 9, 10, 10, 8, 7, 12]\n",
            "[7, 12, 9, 12, 14, 14, 8, 10, 5, 9]\n",
            "[8, 9, 15, 7, 9, 8, 12, 8, 11, 13]\n",
            "[7, 10, 5, 14, 10, 6, 11, 7, 13, 17]\n",
            "[9, 8, 10, 12, 9, 6, 7, 12, 18, 9]\n",
            "[14, 13, 11, 5, 8, 8, 7, 9, 11, 14]\n",
            "[7, 9, 6, 16, 10, 14, 8, 10, 11, 9]\n",
            "[13, 8, 5, 7, 17, 8, 10, 6, 12, 14]\n",
            "[9, 14, 11, 8, 6, 15, 10, 6, 10, 11]\n",
            "[9, 5, 8, 7, 10, 17, 15, 6, 11, 12]\n",
            "[7, 7, 11, 15, 10, 10, 10, 13, 6, 11]\n",
            "[8, 9, 9, 10, 9, 10, 10, 11, 14, 10]\n",
            "[7, 12, 10, 14, 8, 13, 5, 8, 16, 7]\n",
            "[13, 13, 9, 13, 8, 13, 8, 5, 9, 9]\n",
            "[9, 12, 10, 8, 9, 15, 8, 7, 12, 10]\n",
            "[7, 8, 15, 11, 6, 13, 11, 10, 8, 11]\n",
            "[11, 13, 7, 8, 19, 9, 10, 11, 8, 4]\n",
            "[10, 8, 10, 11, 9, 13, 15, 11, 5, 8]\n",
            "[14, 12, 9, 15, 8, 7, 9, 9, 10, 7]\n",
            "[9, 9, 7, 14, 13, 8, 10, 14, 6, 10]\n",
            "[5, 11, 9, 13, 10, 14, 9, 13, 5, 11]\n",
            "[9, 7, 7, 8, 12, 15, 5, 10, 10, 17]\n",
            "[8, 10, 12, 12, 11, 9, 11, 12, 11, 4]\n",
            "[11, 5, 8, 7, 19, 11, 10, 7, 10, 12]\n",
            "[6, 14, 7, 9, 15, 5, 10, 12, 12, 10]\n",
            "[13, 11, 7, 10, 11, 9, 11, 7, 10, 11]\n",
            "[12, 7, 6, 11, 13, 6, 14, 9, 14, 8]\n",
            "[8, 11, 16, 11, 6, 10, 11, 8, 8, 11]\n",
            "[8, 10, 6, 8, 15, 7, 13, 12, 11, 10]\n",
            "[8, 8, 9, 8, 12, 7, 10, 16, 12, 10]\n",
            "[10, 13, 10, 9, 9, 10, 10, 6, 9, 14]\n",
            "[12, 10, 10, 11, 9, 8, 11, 11, 7, 11]\n",
            "[10, 13, 11, 13, 7, 11, 5, 5, 13, 12]\n",
            "[17, 11, 5, 7, 16, 7, 9, 9, 8, 11]\n",
            "[12, 8, 12, 10, 10, 7, 7, 9, 16, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-c65ce39a61ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m  \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1vxtVff5p6sS",
        "colab_type": "code",
        "outputId": "2d8d7fd6-5292-4aa0-f6c6-d05920bff3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "logger = Logger(f'./logs/run_{3_53}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "#find problem\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "  \n",
        "    #forward pass\n",
        "    \n",
        "\n",
        "    \n",
        "    outputs  = model(images)\n",
        "\n",
        "    loss  = criterion(outputs,labels).to(device) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss.backward()\n",
        " \n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "  \n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    if step %1000 ==0:\n",
        "      for tag, value in info.items():\n",
        "        logger.scalar_summary(tag,value,step)\n",
        "        # 2. Log values and gradients of the parameters (histogram summary)\n",
        "      for tag, value in model.named_parameters():\n",
        "          tag = tag.replace('.', '/')\n",
        "          logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "          logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "\n",
        "      # 3. Log training images (image summary)\n",
        "      info = { 'images': images.view(-1,3, 32, 32)[:10].cpu().numpy() }\n",
        "\n",
        "      for tag, images in info.items():\n",
        "          logger.image_summary(tag, images, step)\n",
        "\n",
        "      #pdb.set_trace()\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      print('loss:{}'.format(loss.item()))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.3199999928474426\n",
            "loss:1.8786665201187134\n",
            "accuracy:0.4599999785423279\n",
            "loss:1.5109987258911133\n",
            "accuracy:0.4599999785423279\n",
            "loss:1.6746816635131836\n",
            "accuracy:0.41999998688697815\n",
            "loss:1.5396859645843506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VZ-Zf2Xhm9OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c01d920a-8aab-4882-9285-ee22a9b7e7a5"
      },
      "cell_type": "code",
      "source": [
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.45078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RcNBMPnAfT11",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.4 MNIST diagnosis 2 (10 pts)\n",
        "\n",
        "*Hint:* Look at the test accuracy\n",
        "\n",
        "**Diagnosis: Use the tensorboard to display the training images, it seems that the training data is selective which has a lot of zero than other data**"
      ]
    },
    {
      "metadata": {
        "id": "akcUBX4yrlif",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "AyVlNt9Dt8vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b7a2a17-4cd6-4909-e73c-5b5ea71a49bc"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: http://9553b68e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DeYVw-FQieNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "q_3_4_data_loader = dill.load( open( \"q3_4_loader.p\", \"rb\" ) )\n",
        "# Load the MNIST dataset (images and labels, both train and test) into 2 DataLoaders\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download = True)\n",
        "# load data\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 100,shuffle =True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset,batch_size = 100,shuffle =False)\n",
        "q_3_4_net_loader = dill.load( open( \"q3_4_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_4_net_loader()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1HwPoOE7qLFQ",
        "colab_type": "code",
        "outputId": "a783a0de-071e-4e81-ffc8-8871c294c223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1649
        }
      },
      "cell_type": "code",
      "source": [
        "#problem found\n",
        "\n",
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{3.4}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "# problem fix\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #pdb.set_trace()\n",
        "    #forward pass\n",
        "   \n",
        "    #pdb.set_trace()\n",
        "    outputs  = model(images)\n",
        "    #pdb.set_trace()\n",
        "    loss  = criterion(outputs,labels) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    #pdb.set_trace()\n",
        "    loss.backward()\n",
        "    #pdb.set_trace()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag,value,step)\n",
        "      # 2. Log values and gradients of the parameters (histogram summary)\n",
        "    for tag, value in model.named_parameters():\n",
        "        tag = tag.replace('.', '/')\n",
        "        logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "\n",
        "    # 3. Log training images (image summary)\n",
        "    info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
        "\n",
        "    for tag, images in info.items():\n",
        "        logger.image_summary(tag, images, step)\n",
        "    if step %100 ==0:\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      print('loss:{}'.format(loss.item()))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.8399999737739563\n",
            "loss:0.4967266917228699\n",
            "accuracy:0.8999999761581421\n",
            "loss:0.4229702353477478\n",
            "accuracy:0.9599999785423279\n",
            "loss:0.20248152315616608\n",
            "accuracy:0.9399999976158142\n",
            "loss:0.2676102817058563\n",
            "accuracy:0.9399999976158142\n",
            "loss:0.2403743863105774\n",
            "accuracy:0.9599999785423279\n",
            "loss:0.17210088670253754\n",
            "accuracy:0.9099999666213989\n",
            "loss:0.25721102952957153\n",
            "accuracy:0.9399999976158142\n",
            "loss:0.19654721021652222\n",
            "accuracy:0.9300000071525574\n",
            "loss:0.20346398651599884\n",
            "accuracy:0.949999988079071\n",
            "loss:0.12882602214813232\n",
            "accuracy:0.9399999976158142\n",
            "loss:0.22992286086082458\n",
            "accuracy:0.9699999690055847\n",
            "loss:0.10716312378644943\n",
            "accuracy:0.9399999976158142\n",
            "loss:0.11238694190979004\n",
            "accuracy:0.9699999690055847\n",
            "loss:0.1914239078760147\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.02256031334400177\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.0809394046664238\n",
            "accuracy:0.9799999594688416\n",
            "loss:0.10043692588806152\n",
            "accuracy:0.949999988079071\n",
            "loss:0.14007031917572021\n",
            "accuracy:0.9799999594688416\n",
            "loss:0.06992287933826447\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.027820561081171036\n",
            "accuracy:0.9599999785423279\n",
            "loss:0.10336191207170486\n",
            "accuracy:1.0\n",
            "loss:0.020060162991285324\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.04315892606973648\n",
            "accuracy:0.9699999690055847\n",
            "loss:0.09803590923547745\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.02309010922908783\n",
            "accuracy:1.0\n",
            "loss:0.012100341729819775\n",
            "accuracy:1.0\n",
            "loss:0.005138307809829712\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.022731289267539978\n",
            "accuracy:1.0\n",
            "loss:0.011624421924352646\n",
            "accuracy:1.0\n",
            "loss:0.015174630098044872\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.08832196891307831\n",
            "accuracy:1.0\n",
            "loss:0.005681397393345833\n",
            "accuracy:1.0\n",
            "loss:0.01590147614479065\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.04925351217389107\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.04675963521003723\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.03862190246582031\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.027458813041448593\n",
            "accuracy:0.9799999594688416\n",
            "loss:0.07675305753946304\n",
            "accuracy:0.9799999594688416\n",
            "loss:0.043105028569698334\n",
            "accuracy:1.0\n",
            "loss:0.01133437268435955\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.1098017692565918\n",
            "accuracy:1.0\n",
            "loss:0.010334262624382973\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.02619320899248123\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.014230736531317234\n",
            "accuracy:1.0\n",
            "loss:0.004047604277729988\n",
            "accuracy:1.0\n",
            "loss:0.0023393298033624887\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.02445030026137829\n",
            "accuracy:1.0\n",
            "loss:0.013167940080165863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HHCAj2UoqHkX",
        "colab_type": "code",
        "outputId": "abc93ff6-544a-49d7-d7c0-21b2c93a144a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))\n",
        "    \n",
        "    "
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.9813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2FqPQMhYw6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.5 CIFAR diagnosis 2 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "AVxjpsnOL3N_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Diagnosis: the learning rate for the optimizer is 30000, which is too large**"
      ]
    },
    {
      "metadata": {
        "id": "wPm-3cGFhGMZ",
        "colab_type": "code",
        "outputId": "86a562d1-023f-424c-8d50-501f828a8451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "q_3_5_data_loader = dill.load( open( \"q3_5_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_5_data_loader()\n",
        "q_3_5_net_loader = dill.load( open( \"q3_5_net.p\", \"rb\" ) )\n",
        "net,optimizer = q_3_5_net_loader()\n",
        "model = net.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2BZg-5htLabl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8B1jjrA2qbIj",
        "colab_type": "code",
        "outputId": "f1e0e370-78b6-42ca-e471-e49e01e78610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "logger = Logger(f'./logs/run_{3_53}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "#find problem\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "  \n",
        "    #forward pass\n",
        "    \n",
        "\n",
        "    \n",
        "    outputs  = model(images)\n",
        "\n",
        "    loss  = criterion(outputs,labels).to(device) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss.backward()\n",
        " \n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "  \n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    if step %1000 ==0:\n",
        "      for tag, value in info.items():\n",
        "        logger.scalar_summary(tag,value,step)\n",
        "        # 2. Log values and gradients of the parameters (histogram summary)\n",
        "      for tag, value in model.named_parameters():\n",
        "          tag = tag.replace('.', '/')\n",
        "          logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "          logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "\n",
        "      # 3. Log training images (image summary)\n",
        "      info = { 'images': images.view(-1,3, 32, 32)[:10].cpu().numpy() }\n",
        "\n",
        "      for tag, images in info.items():\n",
        "          logger.image_summary(tag, images, step)\n",
        "\n",
        "      #pdb.set_trace()\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      print('loss:{}'.format(loss.item()))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.3499999940395355\n",
            "loss:1.7990939617156982\n",
            "accuracy:0.38999998569488525\n",
            "loss:1.6045722961425781\n",
            "accuracy:0.3999999761581421\n",
            "loss:1.7973638772964478\n",
            "accuracy:0.4899999797344208\n",
            "loss:1.507317304611206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EBYOjMAeRJFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca80e5c7-bb27-4801-f506-7f079fe956b8"
      },
      "cell_type": "code",
      "source": [
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  net = net.to(device)\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.4311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EpFqb3TT0L37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q3.6 CIFAR diagnosis 3 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "aqa_Aao7PSCR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Diagnosis: The network is too deep which has more than 20 layers,which may be too much for this dataset and will bring overfitting problem. To fix it , I change the network structure the same as Q3.5**"
      ]
    },
    {
      "metadata": {
        "id": "r5a5m0wy0v5b",
        "colab_type": "code",
        "outputId": "17e98ad8-259c-4a31-a985-d56131ba460b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "q_3_6_data_loader = dill.load( open( \"q3_6_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_6_data_loader()\n",
        "\n",
        "q_3_5_net_loader = dill.load( open( \"q3_5_net.p\", \"rb\" ) )\n",
        "net,_ = q_3_5_net_loader()\n",
        "model = net.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkhhcLJ-TkPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "77bc187b-770a-4004-ad4c-183d493792a3"
      },
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q_3_5_net(\n",
            "  (fc1): Linear(in_features=3072, out_features=8192, bias=True)\n",
            "  (fc2): Linear(in_features=8192, out_features=4096, bias=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "  (fc4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ncAPNLPjTEgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "363b8236-a299-4e81-dfab-5d48d2190de8"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "logger = Logger(f'./logs/run_{3_53}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "#find problem\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "  \n",
        "    #forward pass\n",
        "    \n",
        "\n",
        "    \n",
        "    outputs  = model(images)\n",
        "\n",
        "    loss  = criterion(outputs,labels).to(device) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss.backward()\n",
        " \n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "  \n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    if step %1000 ==0:\n",
        "      for tag, value in info.items():\n",
        "        logger.scalar_summary(tag,value,step)\n",
        "        # 2. Log values and gradients of the parameters (histogram summary)\n",
        "      for tag, value in model.named_parameters():\n",
        "          tag = tag.replace('.', '/')\n",
        "          logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "          logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "\n",
        "      # 3. Log training images (image summary)\n",
        "      info = { 'images': images.view(-1,3, 32, 32)[:10].cpu().numpy() }\n",
        "\n",
        "      for tag, images in info.items():\n",
        "          logger.image_summary(tag, images, step)\n",
        "\n",
        "      #pdb.set_trace()\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      print('loss:{}'.format(loss.item()))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.32999998331069946\n",
            "loss:1.8425071239471436\n",
            "accuracy:0.5299999713897705\n",
            "loss:1.4569816589355469\n",
            "accuracy:0.5099999904632568\n",
            "loss:1.4345391988754272\n",
            "accuracy:0.5399999618530273\n",
            "loss:1.3951600790023804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vePKXI7mWrTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "289bbead-f15a-442c-acc2-a22d0331899e"
      },
      "cell_type": "code",
      "source": [
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  net = net.to(device)\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.4799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7dse7oiK7wPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q 3.7 MNIST diagnosis 3 (10 pts)"
      ]
    },
    {
      "metadata": {
        "id": "tR29oJbNGS2S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Diagnosis: It seems that the labels for the dataset is wrong. To fix it, we change the dataset to the dataset in Q3.2.**"
      ]
    },
    {
      "metadata": {
        "id": "7vA-AFXY0v_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_3_7_data_loader = dill.load( open( \"q3_2_loader.p\", \"rb\" ) )\n",
        "train_loader, test_loader = q_3_7_data_loader()\n",
        "q_3_7_net_loader = dill.load( open( \"q3_7_net.p\", \"rb\" ) )\n",
        "net, optimizer = q_3_7_net_loader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BwiHfrix9DTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f15982f1-c283-4cd4-a5ba-c2a1c1937a4a"
      },
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q_3_7_net(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2h4DJWLnqh1_",
        "colab_type": "code",
        "outputId": "cadd54c3-d054-46fa-a9c9-424236c53896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "#problem found\n",
        "\n",
        "num_epochs = 8\n",
        "from hw1.helper import Logger\n",
        "import time, datetime\n",
        "import pdb\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{3.72}/') \n",
        "\n",
        "# loss \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "\n",
        "# problem fix\n",
        "model = net.to(device)\n",
        "\n",
        "\n",
        "               \n",
        "for i in range(num_epochs):\n",
        "  for j,(images,labels)  in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #pdb.set_trace()\n",
        "    #forward pass\n",
        "   \n",
        "    #pdb.set_trace()\n",
        "    outputs  = model(images)\n",
        "    #pdb.set_trace()\n",
        "    loss  = criterion(outputs,labels) # pos can't be reverted because need preprocessing for outputs\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    #pdb.set_trace()\n",
        "    loss.backward()\n",
        "    #pdb.set_trace()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # record the accuracy and loss\n",
        "    step = step +1\n",
        "   # pdb.set_trace()\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    accuracy  =  (labels == predicted).float().mean()\n",
        "    info  = {'loss':loss.item(),'accuracy':accuracy.item()}\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag,value,step)\n",
        "      # 2. Log values and gradients of the parameters (histogram summary)\n",
        "    for tag, value in model.named_parameters():\n",
        "        tag = tag.replace('.', '/')\n",
        "        logger.histo_summary(tag, value.data.cpu().numpy(), step)\n",
        "        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step)\n",
        "    #pdb.set_trace()\n",
        "    # 3. Log training images (image summary)\n",
        "    info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
        "\n",
        "    for tag, images in info.items():\n",
        "        logger.image_summary(tag, images, step)\n",
        "        \n",
        "    for i in range(10):\n",
        "      \n",
        "      logger.scalar_summary('label:'+str(i),labels[i].item(),step)\n",
        "    \n",
        "\n",
        "    if step %100 ==0:\n",
        "      print('accuracy:{}'.format(accuracy.item()))\n",
        "      print('loss:{}'.format(loss.item()))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:0.8700000047683716\n",
            "loss:0.4446192681789398\n",
            "accuracy:0.9799999594688416\n",
            "loss:0.21155518293380737\n",
            "accuracy:0.9599999785423279\n",
            "loss:0.1697012186050415\n",
            "accuracy:0.9699999690055847\n",
            "loss:0.13947707414627075\n",
            "accuracy:0.9899999499320984\n",
            "loss:0.05399828031659126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YwvoXH3l9iUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2abb03ef-5da5-4034-cbf3-cd3f502daa23"
      },
      "cell_type": "code",
      "source": [
        "# check test accuracy\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total  = 0\n",
        "  net = net.to(device)\n",
        "  for images,labels in test_loader:\n",
        "    images= images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(images)\n",
        "    #pdb.set_trace()\n",
        "    _,predicted  = torch.max(outputs.data,1)\n",
        "    correct +=  (labels == predicted).sum().item()\n",
        "    total += labels.size(0)\n",
        "    \n",
        "  print('accuracy of the network for testing data is:{}'.format(correct/total))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the network for testing data is:0.922\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}